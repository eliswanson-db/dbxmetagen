{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f013bb74-d1af-4860-8844-8490aaa63a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ../../requirements.txt\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb78826f-c581-4ed0-9052-cee6e2dad4bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import logging\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "instance_name = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('browserHostName')\n",
    "DATABRICKS_INSTANCE = f\"https://{instance_name}\"\n",
    "TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "CURRENT_PATH = os.getcwd()\n",
    "NOTEBOOK_PATH = os.path.join(Path(CURRENT_PATH).parent.parent, \"notebooks\")\n",
    "NODE_TYPE_ID = \"Standard_DS3_v2\"\n",
    "CATALOG_NAME = \"dbxmetagen\"\n",
    "SCHEMA_NAME = \"metadata_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4824b774-59c8-45b3-afca-0d52b926ed43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def sanitize_email(email: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace all non-alphanumeric characters in the email with underscores.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-zA-Z0-9]', '_', email)\n",
    "\n",
    "def get_current_date_str() -> str:\n",
    "    \"\"\"\n",
    "    Get current date as YYYYMMDD (no hyphens).\n",
    "    \"\"\"\n",
    "    return datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "def list_files_with_extensions(folder: str, extensions: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    List files in a folder with given extensions.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        logger.warning(f\"Folder does not exist: {folder}\")\n",
    "        return []\n",
    "    return [\n",
    "        f for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f)) and any(f.lower().endswith(ext) for ext in extensions)\n",
    "    ]\n",
    "\n",
    "def count_rows_in_file(filepath: str) -> Tuple[int, Optional[bool]]:\n",
    "    \"\"\"\n",
    "    Count the number of rows in a file. Returns (row_count, has_header).\n",
    "    Supports .xlsx, .tsv, .sql.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(filepath)[1].lower()\n",
    "    try:\n",
    "        if ext == \".xlsx\":\n",
    "            df = pd.read_excel(filepath)\n",
    "            return len(df), True\n",
    "        elif ext == \".tsv\":\n",
    "            df = pd.read_csv(filepath, sep='\\t')\n",
    "            return len(df), True\n",
    "        elif ext == \".sql\":\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            # Heuristic: .sql files may not have a header\n",
    "            return len(lines), False\n",
    "        else:\n",
    "            logger.warning(f\"Unsupported file extension: {ext}\")\n",
    "            return 0, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to count rows in {filepath}: {e}\")\n",
    "        return 0, None\n",
    "\n",
    "def ensure_empty_folder(folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Ensure the folder exists and is empty.\n",
    "    \"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    for f in os.listdir(folder):\n",
    "        path = os.path.join(folder, f)\n",
    "        try:\n",
    "            if os.path.isfile(path):\n",
    "                os.remove(path)\n",
    "            elif os.path.isdir(path):\n",
    "                shutil.rmtree(path)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to clean folder {folder}: {e}\")\n",
    "\n",
    "def copy_file(src: str, dst_folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Copy a file to the destination folder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        shutil.copy2(src, dst_folder)\n",
    "        logger.info(f\"Copied {src} to {dst_folder}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to copy {src} to {dst_folder}: {e}\")\n",
    "\n",
    "def main(\n",
    "    base_volume_path: str,\n",
    "    current_user: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Main workflow for file checking and management.\n",
    "    \"\"\"\n",
    "    sanitized_user = sanitize_email(current_user)\n",
    "    date_str = get_current_date_str()\n",
    "    user_folder = os.path.join(base_volume_path, sanitized_user)\n",
    "    date_folder = os.path.join(user_folder, date_str)\n",
    "    reviewed_outputs_folder = os.path.join(user_folder, \"reviewed_outputs\")\n",
    "    run_logs_folder = os.path.join(date_folder, \"exportable_run_logs\")\n",
    "\n",
    "    extensions = [\".xlsx\", \".tsv\", \".sql\"]\n",
    "    files = list_files_with_extensions(date_folder, extensions)\n",
    "    logger.info(f\"Found {len(files)} file(s) in {date_folder}: {files}\")\n",
    "\n",
    "    for f in files:\n",
    "        path = os.path.join(date_folder, f)\n",
    "        row_count, _ = count_rows_in_file(path)\n",
    "        logger.info(f\"File: {f} | Rows: {row_count}\")\n",
    "\n",
    "    run_log_files = list_files_with_extensions(run_logs_folder, extensions)\n",
    "    if len(run_log_files) != 1:\n",
    "        logger.error(f\"Expected 1 file in {run_logs_folder}, found {len(run_log_files)}\")\n",
    "        return\n",
    "    run_log_file = run_log_files[0]\n",
    "    run_log_path = os.path.join(run_logs_folder, run_log_file)\n",
    "    row_count, has_header = count_rows_in_file(run_log_path)\n",
    "    logger.info(f\"Run log file: {run_log_file} | Format: {os.path.splitext(run_log_file)[1]} | Rows: {row_count} | Header: {has_header}\")\n",
    "\n",
    "    ensure_empty_folder(reviewed_outputs_folder)\n",
    "\n",
    "    copy_file(run_log_path, reviewed_outputs_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    current_user = sanitize_email(spark.sql(\"SELECT current_user()\").collect()[0][0])\n",
    "    base_volume_path = f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/generated_metadata/\"\n",
    "    main(base_volume_path, current_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89eed8b6-3b08-4fb0-bfea-e53425524451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "review_integration_tests",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
