variables:
  catalog_name:
    description: Target catalog where data, models, and files are stored for this project. If source tables are in this catalog, then table names only have to be scoped with schema and table. If table names are in other catalogs then table names need to be fully scoped.
    default: dbxmetagen
  host:
    description: Base url host variable. If using asset bundles, will get overridden by target host. Otherwise, use the host here that you want to target.
    default: https://adb-830292400663869.9.azuredatabricks.net/
  catalog_tokenizable:
    description: tokenizable catalog name. You can add string formatting here for environment. For example, add _{env} so that config.env from widgets or from the asset bundle variables gets parameterized with the catalog name.
    default: __CATALOG_NAME__
  format_catalog:
    description: Whether or not to string format any bracketed variables in catalog name. If set to false, then __CATALOG_NAME__{env} will keep the _{env} suffix, if not it will be formatted with the current environment.
    default: false
  model:
    description: LLM endpoint used by model calls. Note that this is not the same as any registered model in UC that wraps the prompt engineering work, but is the serving endpoint called after prompt engineering. This can be changed to other served models as well as provisioned throughput models or external models for compliance purposes if needed.
    default: databricks-meta-llama-3-1-70b-instruct    
  apply_ddl:
    description: Whether to apply DDL directly to the specified environment or not. Modify permissions needed, and be aware that this will alter tables.
    default: false
  allow_data:
    description: Whether to allow data in comments. Note that this does not prevent data from being used in the inputs, but is meant to keep data from the outputs.
    default: true
  pi_classification_rules:
    description: rules for PI classification
    default: |
      PII (Personally Identifiable Information): Any data that can identify an individual, such as name, address, or social security number. PHI (Protected Health Information): Health-related data that includes any of the 18 HIPAA-identified elements, like medical records or treatment histories. PCI (Payment Card Information): Data related to payment card transactions, including card numbers, expiration dates, and security codes. Non-PII/PHI/PCI: Data that cannot be used to identify an individual or is not related to health or payment cards, such as general demographics or anonymized statistics.
      ###
      To identify these types:
      ###
      PII: Look for column names or data containing personal details like 'full_name', 'address', 'ssn', 'email', or 'phone_number'.
      PHI: Search for health-related terms in column names or data, such as 'medical_record_number', 'diagnosis', 'treatment_date', or any of the 18 HIPAA identifiers.
      PCI: Identify columns or data with payment card-related terms like 'card_number', 'expiration_date', 'cvv', or 'cardholder_name'.
      Non-PII/PHI/PCI: Look for general, non-identifying information like 'zip_code' (without other identifiers), 'age_group', or 'product_category'.
      ###
      Tables with PII vs columns with PII:
      ###
      If a column has only PII, then it should be considered only PII, even if other columns in the table have medical information in them. A specific example of this is that if a column only contains name, or address, then it should be marked as pii, not as phi. However, the column containing medical information would be considered PHI because it pertains to the health status, provision of health care, or payment for health care that can be linked to an individual.

      If a table has columns with both PII and PHI, or with PII and medical information, then the table itself has PHI.
  allow_manual_override:
    description: Whether to allow manual overrides to fields. manual override csv allows overrides to be specified in a CSV.
    default: true
  override_csv_path:
    description: Path and name of csv to be used for manual overrides.
    default: metadata_overrides.csv
  tag_none_fields:
    description: Whether to tag fields with no PI, or not apply any tags. If a field is classified as 'None' in PI, it won't get tagged.
    default: true
  max_prompt_length:
    description: maximum prompt length
    default: 5000
  columns_per_call:
    description: columns per call
    default: 5
  sample_size:
    description: sample size
    default: 5
  max_tokens:
    description: maximum tokens
    default: 5000
  temperature:
    description: temperature
    default: 0.1
  add_metadata:
    description: Whether to use metadata from information schema and from a DESCRIBE EXTENDED on each column or not. The most information will be used if ANALYZE ALL COLUMNS is run on the table. Setting add_metadata to true will also lead to a slower process.
    default: true
  acro_content:
    description: acronyms that are commonly used in the data
    default: |
        {
        "DBX": "Databricks",
        "WHO": "World Health Organization",
        }
  schema_name:
    description: Primary schema where data, models, and files are written to for this project. This is not the source schema, which is specified elsewhere with the source table name.
    default: metadata_results
  volume_name:
    description: volume name in which to store DDL files.
    default: generated_metadata
  registered_model_name:
    description: registered model name
    default: default
  model_type:
    description: Model type
    default: default
  table_names_source:
    description: Path variable to table names. Don't edit unless you know what you're doing.
    default: csv_file_path
  source_file_path:
    description: Path to the source file used in identifying table names.
    default: table_names.csv
  current_user:
    description: User deploying the bundle. Can apply to service principals as well.
    default: ${workspace.current_user.userName}
  current_working_directory:
    description: Working directory or bundle root.
    default: /Users/${var.current_user}/.bundle/${bundle.name}/${bundle.target}
  control_table:
    description: Control table name.
    default: "metadata_control_{}"
  dry_run:
    description: Whether to perform a dry run. Not yet implemented, though if volume_name is set to null and apply_ddl is set to false this effectively is a dry run. Similarly, just setting apply_ddl to false is in a way a dry run.
    default: false
  pi_column_field_names:
    description: Field names for PI columns. Not yet implemented. Will allow name changes and alternate schemas for tag names. Currently, the code must be changed.
    default: default